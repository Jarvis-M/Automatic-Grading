
# 研究生实践项目任务书
自动批改 C++ 程序设计作业系统（两组并行对抗开发）

## 1. 项目背景与目标
- **背景**：C++ 程序设计课程作业以手写纸质为主，教师批改耗时、标准不一、反馈滞后。通过计算机视觉与大语言模型技术，实现拍照到自动评分的流程自动化。
- **总体目标**：构建“拍照—识别—编译—测试—智能评分—改进建议”全链路系统，支持批量处理与可解释评分，帮助教师提效、学生获得即时反馈。
- **验收目标（关键指标）**：
  - 端到端处理成功率（从照片到编译运行）≥ 85%（在标准化拍摄条件下）
  - OCR 字符错误率 CER ≤ 3.0%，关键标记（如 `{}`, `()`, `;`）识别准确率 ≥ 98%
  - 编译成功率（在无语义错误样本上）≥ 95%
  - 测试通过率统计准确，判题误差为 0
  - 智能评分与人工评分皮尔逊相关系数 ≥ 0.8
  - 单份作业平均处理时延 ≤ 8 秒（含 OCR、编译、测试、评分）

## 2. 开发范围（功能清单）
1) **作业电子化（拍照导入）**
   - 手机拍摄/相册导入，支持多页
   - 自动裁切、矫正、去阴影、去透印、去噪
2) **手写 C++ 程序识别**
   - 代码区域检测与分割（区分题目描述与代码）
   - 行/块级切分、OCR 识别、符号敏感纠错
   - 语言感知纠错（C++ 关键字/标识符/括号/分号）
3) **编译与执行**
   - 生成 `.cpp` 文件，`g++ -std=c++17` 或 `clang++` 编译
   - Docker 沙箱隔离，资源限额（CPU/内存/时限），禁网
   - 测试数据注入，判题与结果解析
4) **智能评分与改进建议**
   - 基于规则的基准评分（编译/测试/风格/复杂度）
   - 调用 DeepSeek API 进行综合评分与建议
   - 多源融合评分与可解释报告
5) **批量与管理**
   - 批量导入与处理进度监控
   - 作业版本记录、日志与错误分析
   - 教师端导出成绩与反馈

## 3. 技术路线与系统架构
- **整体架构**：前端 App（或 Web 上传） → 图像预处理 → 代码区域检测 → OCR 识别 → 语法感知纠错 → 代码生成 → Sandbox 编译执行 → 规则评分 → DeepSeek 评分 → 融合与报告 → 存储与导出
- **关键技术**：
  - 图像处理：OpenCV（去噪、二值化 Otsu/Sauvola、自适应阈值、透视矫正、色彩均衡、形态学处理）
  - 代码检测与 OCR：Detectron2/YOLOv8（区域检测，可选），CRNN/SATRN/ViT-Seq2Seq，或 TrOCR/Donut（Transformer 端到端）；PaddleOCR 手写模型可作为 baseline
  - 语言感知纠错：C++ 关键字词典 + n-gram/小型字符级语言模型 + 编译器错误驱动修复；`clang-format` 统一格式；`tree-sitter-cpp`/`clangd` 辅助语法校验
  - 编译执行：Docker + g++/clang++，`ulimit`，超时与内存限制，I/O 重定向
  - 测试与评分：自定义判题器，GoogleTest/pytest harness；静态分析（clang-tidy），复杂度（lizard）
  - 智能评分：DeepSeek API（需要密钥与配额），提示工程与评分量表融合
- **数据存储**：MinIO/本地 NAS（图片、报告），PostgreSQL/SQLite（元数据、成绩、日志）

## 4. 任务分组与分工（10 名同学，2 组对抗开发）
- **分组方式**：10 名同学分为两组，每组 5 人，承担相同目标与范围，独立实现并竞争。
- **小组角色建议（每组）**：
  - 组长/PM（1）：需求拆解、进度管理、里程碑与对外交付
  - 视觉与 OCR 负责人（1）：图像预处理、检测、识别、纠错
  - 编译与沙箱负责人（1）：容器化、资源控制、测试框架
  - 后端集成与数据负责人（1）：服务编排、API、数据库、日志
  - 评分与 LLM 负责人（1）：规则评分、DeepSeek prompt、融合报告
- **人员指派模板（示例）**：
  - A 组（5人）：PM：TBD；OCR：TBD；编译：TBD；后端：TBD；LLM/评分：TBD
  - B 组（5人）：PM：TBD；OCR：TBD；编译：TBD；后端：TBD；LLM/评分：TBD

## 5. 时间计划与里程碑（8 周建议）
- 第 1 周：需求澄清与方案评审；数据采集规范；环境与仓库初始化；基线 OCR 流水线
- 第 2 周：预处理与区域检测 MVP；代码行切分与符号敏感 OCR；Docker 沙箱搭建
- 第 3 周：语法感知纠错 v1（关键词词典 + 括号/分号修复）；编译与用例执行 MVP
- 第 4 周：端到端 v1 打通（照片→评分）；规则评分引擎 v1；DeepSeek 接口打通（沙箱/干跑）
- 第 5 周：精度与鲁棒性迭代（数据增强、模型微调）；测试集与基准建立
- 第 6 周：可解释报告 v1；性能优化与批量处理；错误分析仪表盘
- 第 7 周：综合联调与预答辩；对抗评测（公开集）；修复与封版候选
- 第 8 周：最终评测（隐藏集）；答辩与对抗演示；文档归档与移交

## 6. 数据与采集规范
- **拍摄规范**：
  - 光照均匀、避免强反光与阴影；保证满幅包含作业边界
  - 分辨率≥12MP；尽量正对纸面，尽量单色背景
  - 每页仅包含一份作业，标注题号与页码
- **标注与数据集**：
  - 采集 300–500 份真实作业图像，覆盖不同字迹与纸张
  - 标注代码区域（矩形/多边形），并保存纯文本真值
  - 合成数据：使用手写字体集渲染 C++ 语料以增强符号样本
- **数据划分**：训练/验证/公开评测/隐藏评测，避免泄漏
- **合规**：脱敏（姓名、学号马赛克），采集与使用经同意

## 7. 关键模块设计细则
### 7.1 图像预处理
- 步骤：白平衡 → 高斯/双边去噪 → 自适应阈值/二值化（Otsu/Sauvola）→ 透视矫正（霍夫线/四点变换）→ 形态学开闭运算 → 对比度拉伸
- 抗干扰：阴影去除（背景估计/形态学顶帽）、去网格线、边缘裁切

### 7.2 区域检测与行切分
- 方案 A：轻量 YOLOv8 检测代码块 + 连通域行切分
- 方案 B：投影法/DocTR 行分析基线
- 注意区分题目描述与代码（关键特征：等宽字符、分号/括号密度）

### 7.3 OCR 与语法感知纠错
- 模型选择：CRNN/SATRN/TrOCR（手写微调）
- 纠错策略：
  - 词典约束：C++ 关键字、常见库名、操作符词表
  - 标点优先：`{}()[];,:<>*&#43;-/=!"'` 等高权重字符 beam-search 约束
  - 编译器驱动修复：利用编译错误定位字符级疑点，迭代最小编辑修复
  - 格式化与语法树：`clang-format`、`tree-sitter-cpp` 校验结构闭合

### 7.4 编译与沙箱
- Docker 容器，无网络，CPU/内存/时限限制，seccomp/AppArmor
- 编译参数：`g++ -std=c++17 -O2 -pipe -static -s`（静态可选）；捕获编译日志
- 运行：超时（TLE），崩溃（RE），输出比对（AC/WA），判题器支持多组输入

### 7.5 规则评分与 DeepSeek 融合
- 规则评分维度：
  - 可编译性（20）：能否一次编译通过；错误类型与数量
  - 正确性（40）：测试通过率（权重按样例/隐藏测试）
  - 代码质量（20）：命名、格式、复杂度、边界处理、冗余
  - 鲁棒性（10）：异常处理、输入校验
  - 文档与可读性（10）：注释、结构清晰度
- DeepSeek 评分：
  - 输入：题目描述、识别代码、编译/运行日志、测试结果摘要
  - Prompt 设计：提供评分细则、严禁泄露标准答案、输出结构化 JSON（分项分数与建议）
  - 风控：超时、重试、速率限制与成本预算
- 融合方式：加权平均或基于置信度的动态融合，阈值冲突触发人工复核

### 7.6 报告与可解释性
- 输出内容：总分、分项得分、关键证据（失败测试用例、日志片段、可视化行差异）、改进建议清单
- 导出：PDF/HTML/CSV；批量成绩汇总

## 8. 开发环境与仓库规范
- 语言：Python 3.10+（CV/OCR/服务）、C++17（样例与测试程序）
- 依赖：OpenCV、PyTorch/ONNXRuntime、PaddleOCR（可选）、FastAPI、Docker、PostgreSQL/SQLite、MinIO、`tree-sitter`、`clang-format`、`clang-tidy`
- 目录结构建议：
  ```
  /project
    /data               # 原始与标注数据
    /preprocess         # 图像预处理
    /detector           # 区域检测
    /ocr                # 识别与纠错
    /compiler           # 编译与沙箱
    /judge              # 判题与测试
    /scoring            # 规则评分与融合
    /llm                # DeepSeek 调用与提示工程
    /api                # FastAPI 服务
    /ui                 # 前端/上传工具
    /scripts            # 训练/评测/工具脚本
    /docs               # 设计、报告、说明
    /configs            # 配置与权重
    /tests              # 单元/集成测试
  ```
- 代码规范：PEP8/clang-format，提交前 CI 检查（lint、tests）

## 9. 评测与竞赛规则
- **公开评测集**：用于开发期对齐
- **隐藏评测集**：最终评分使用，覆盖噪声、斜拍、多字迹
- **主指标**（总分 100）：
  - 功能完整性与稳定性：40
  - 识别与编译准确性：25（CER、关键符号召回、编译成功率、端到端成功率）
  - 正确性评测与评分一致性：15（测试通过统计、与人工相关性）
  - 性能与可扩展性：10（延迟、吞吐、资源占用）
  - 工程质量与文档：5
  - 创新性与演示表现：5
- **胜负判定**：以隐藏评测集总分高者为胜。若分差 ≤ 2 分，比较端到端成功率与延迟；仍相同则并列。
- **对抗演示**：现场随机拍摄若干作业，实时跑通流程。

## 10. 验收标准（硬性门槛）
- 端到端自动化，无人工干预即可完成至少 50 份作业的批量处理
- 安全合规：容器禁网、资源受限、个人信息脱敏；无越权文件访问
- 可复现实验：一键部署脚本与评测脚本，结果与报告可复验
- 文档齐全：架构说明、安装指南、API 文档、数据与评测说明、用户手册

## 11. 风险与缓解
- 手写体多样性导致 OCR 精度不足 → 扩充/微调数据、字符集加权、编译器驱动纠错
- 光照/透视复杂场景 → 强化预处理、引导拍摄规范、数据增强
- 运行安全风险 → 强化沙箱、禁网、只读挂载、系统调用白名单
- LLM 评分不稳定/成本高 → 规则评分兜底、缓存与批量化、调用上限与降级策略
- 进度风险 → 每周评审与可运行增量，早打通、早闭环

## 12. 隐私与伦理
- 作业图片“最小化采集”，仅用于教学与模型改进
- 统一脱敏策略；按需访问权限
- 评分可解释并允许复议；避免 LLM 作为唯一评分依据

## 13. 交付物清单
- 源码与可执行部署包（Dockerfile、Compose/Helm 可选）
- 模型权重与配置、数据字典与词表
- 数据集说明（采集、划分、标注规范）
- 评测与基准脚本、最终报告（PDF/HTML）
- 使用手册（教师/学生）
- 演示视频与答辩材料

## 14. DeepSeek API 接入说明（占位指引）
- 准备：申请 API Key（由导师统一或各组申请），配置在服务端安全存储
- 接口封装：
  - 入参：题目、识别代码、编译/运行日志、测试摘要、评分量表
  - 出参：结构化 JSON（各维度分数、总分、证据、建议、置信度）
- 示例 Prompt 结构（摘要）：
  ```
  你是严谨的编程作业助教。请基于评分细则对下述 C++ 作业给出分项评分与改进建议。
  评分细则：{rubric}
  题目：{problem}
  学生代码（OCR）：{code}
  编译日志：{compile_log}
  运行摘要：{run_summary}
  输出 JSON：
  {
    "scores": {...}, "total": 0-100, "rationale": "...", "suggestions": ["...", "..."]
  }
  ```
- 速率与成本：批量任务采用队列与并发控制；失败重试与降级到规则评分

## 15. 最低可行产品（MVP）定义
- 单页清晰作业照片 → 稳定识别代码（含符号）→ 成功编译 → 跑通 3–5 个样例 → 规则评分 + DeepSeek 建议 → 生成可读报告

## 16. 加分项（可选）
- 多页合并与跨页代码识别
- 版式/题号自动解析与题目匹配
- 语义误差定位与自动修复建议（变量命名、边界条件）
- 教师端可视化看板（吞吐、错误热力、样本回放）

## 17. 行动要求（本周）
- 完成人员分组与角色明确，提交甘特图
- 建立共享数据仓与命名规范
- 交付：预处理与 OCR baseline（可离线），Docker 沙箱原型，DeepSeek 干跑脚手架

—— 以上为正式项目任务书，两组独立开发、同台竞赛，按时里程碑评审与打靶迭代。
